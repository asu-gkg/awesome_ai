{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0e8203-eca3-4a43-971c-a116704ccf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting kaggle\n",
      "  Downloading kaggle-1.6.14.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m152.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: python-slugify in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: bleach in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from bleach->kaggle) (23.2)\n",
      "Requirement already satisfied: webencodings in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests->kaggle) (3.7)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.14-py3-none-any.whl size=105119 sha256=7e1bb6df43102a2a471ac39b09308ac67733e63dd68d9f53a6094ece9712f347\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/d7/54/06/8a8f40cb39536605feb9acaacd0237a95eba39e5065e6392f4\n",
      "Successfully built kaggle\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: kaggle\n",
      "Successfully installed kaggle-1.6.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed04a48-be16-428f-a04f-71a8d1938c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('./titanic/train.csv')\n",
    "test_data = pd.read_csv('./titanic/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c80099-5749-4e80-961f-8cb32be26f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "print(train_data.info())\n",
    "print(train_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9ef88b-e460-4f0c-8a55-59cd61cd4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值\n",
    "train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
    "train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)\n",
    "train_data.drop(['Cabin'], axis=1, inplace=True)  # Cabin列缺失值过多，直接删除\n",
    "\n",
    "# 对测试集进行同样的处理\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].median(), inplace=True)\n",
    "test_data.drop(['Cabin'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c5168e-ee41-4d1e-b0f9-8bc1022eaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将性别和登船港口转为数值\n",
    "train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# 选择特征\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S']\n",
    "X = train_data[features]\n",
    "y = train_data['Survived']\n",
    "X_test = test_data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cda27fd-d9b8-4062-ad63-9aec6be3737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2bb8f2-9bce-4fe5-98c3-0bfe546ed74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82737724 -0.56573646  0.43279337 ...  0.73769513 -0.30756234\n",
      "   0.61583843]\n",
      " [-1.56610693  0.66386103  0.43279337 ... -1.35557354 -0.30756234\n",
      "  -1.62380254]\n",
      " [ 0.82737724 -0.25833709 -0.4745452  ... -1.35557354 -0.30756234\n",
      "   0.61583843]\n",
      " ...\n",
      " [ 0.82737724 -0.1046374   0.43279337 ... -1.35557354 -0.30756234\n",
      "   0.61583843]\n",
      " [-1.56610693 -0.25833709 -0.4745452  ...  0.73769513 -0.30756234\n",
      "  -1.62380254]\n",
      " [ 0.82737724  0.20276197 -0.4745452  ...  0.73769513  3.25137334\n",
      "  -1.62380254]]\n",
      "(891, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07fe8c38-154f-46c6-89ad-3db71935d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574a443c-1696-4356-99b1-95be4cc1529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927d8076-96ab-4638-abf4-99f79f833d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100558659217877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       105\n",
      "           1       0.79      0.74      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred)}\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df855ce5-df24-4a04-b71d-66ffbba7577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a659e9d3-fcd1-404a-9dde-68197d9e88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data[\"PassengerId\"],\n",
    "    \"Survived\": test_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afb6e377-7711-41b7-b9f1-eb92c156639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "643061d6-eba6-4e34-9c8c-eb57bcf26ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting autogluon\n",
      "  Downloading autogluon-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.1.0 (from autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading autogluon.core-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.features==1.1.0 (from autogluon)\n",
      "  Downloading autogluon.features-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.1.0 (from autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading autogluon.tabular-1.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.multimodal==1.1.0 (from autogluon)\n",
      "  Downloading autogluon.multimodal-1.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.1.0 (from autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading autogluon.timeseries-1.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<1.29,>=1.21 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (1.23.5)\n",
      "Requirement already satisfied: scipy<1.13,>=1.5.4 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (1.10.1)\n",
      "Collecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (3.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2.0.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (4.66.4)\n",
      "Requirement already satisfied: requests in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (3.7.2)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading boto3-1.34.126-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting autogluon.common==1.1.0 (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading autogluon.common-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: Pillow<11,>=10.0.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (10.3.0)\n",
      "Collecting torch<2.2,>=2.1 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting lightning<2.2,>=2.1 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading lightning-2.1.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.39.0,>=4.38.0 (from transformers[sentencepiece]<4.39.0,>=4.38.0->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jsonschema<4.22,>=4.18 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (4.19.2)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: evaluate<0.5.0,>=0.4.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (0.4.0)\n",
      "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torchvision<0.17.0,>=0.16.0 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (1.3)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (3.8.1)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (3.1.4)\n",
      "Requirement already satisfied: tensorboard<3,>=2.9 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.multimodal==1.1.0->autogluon) (2.16.2)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading fastai-2.7.15-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon) (1.4.0)\n",
      "Collecting pytorch-lightning<2.2,>=2.1 (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading pytorch_lightning-2.1.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts<0.14.4,>=0.14.0 (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading gluonts-0.14.3-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.common==1.1.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (5.9.0)\n",
      "Requirement already satisfied: setuptools in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from autogluon.common==1.1.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.0->autogluon) (23.2)\n",
      "Requirement already satisfied: pyyaml in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.0->autogluon) (6.0.1)\n",
      "Collecting botocore<1.35.0,>=1.34.126 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading botocore-1.34.126-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting plotly (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: six in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon) (1.16.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (2.19.1)\n",
      "Requirement already satisfied: dill in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.23.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.13.3)\n",
      "Requirement already satisfied: pip in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (24.0)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.6,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading fastcore-1.5.45-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting spacy<4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading spacy-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting pydantic<3,>=1.7 (from gluonts<0.14.4,>=0.14.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting toolz~=0.10 (from gluonts<0.14.4,>=0.14.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from gluonts<0.14.4,>=0.14.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon) (4.11.0)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting cloudpickle (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.0->autogluon) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (0.10.6)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting numba (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.0->autogluon) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.0->autogluon) (2023.10.3)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: colorama in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.4.6)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: rich in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (13.3.5)\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon) (1.12)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon) (3.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2023.3)\n",
      "Requirement already satisfied: filelock in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (3.13.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: aiosignal in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (1.2.0)\n",
      "Requirement already satisfied: frozenlist in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (1.4.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (3.9.5)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (0.14.1)\n",
      "Collecting smart-open (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading virtualenv-20.26.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (1.48.2)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (14.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (2024.6.2)\n",
      "Collecting imageio>=2.4.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading tifffile-2024.5.22-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting lazy_loader>=0.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (3.5.0)\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (2.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (3.0.3)\n",
      "Requirement already satisfied: safetensors in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.0->autogluon) (0.4.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.1.0 (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.39.0,>=4.38.0->transformers[sentencepiece]<4.39.0,>=4.38.0->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.39.0,>=4.38.0->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon) (3.0.9)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (4.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon) (4.12.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.7->gluonts<0.14.4,>=0.14.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1.7->gluonts<0.14.4,>=0.14.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading thinc-8.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.0->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (3.10.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (2.15.1)\n",
      "Collecting wrapt (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.0->autogluon) (1.3.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (2.29.0)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.1.0)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon) (2.5)\n",
      "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting setuptools (from autogluon.common==1.1.0->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tqdm<5,>=4.38 (from autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore<1.35.0,>=1.34.126->boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting requests[socks] (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading requests-2.30.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading requests-2.29.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon) (1.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (4.7.2)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon)\n",
      "  Downloading marisa_trie-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon)\n",
      "  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.0->autogluon.core[all]==1.1.0->autogluon)\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (42.0.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.0->autogluon) (0.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (2.21)\n",
      "Downloading autogluon-1.1.0-py3-none-any.whl (9.7 kB)\n",
      "Downloading autogluon.core-1.1.0-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.features-1.1.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.multimodal-1.1.0-py3-none-any.whl (427 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.5/427.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.tabular-1.1.0-py3-none-any.whl (308 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.timeseries-1.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.1/147.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.common-1.1.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.126-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading fastai-2.7.15-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gluonts-0.14.3-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.1.4-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
      "Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading pytorch_lightning-2.1.4-py3-none-any.whl (778 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading botocore-1.34.126-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastcore-1.5.45-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2024.5.22-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.5/225.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading thinc-8.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openxlab-0.1.0-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.4/307.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval, oss2, aliyun-python-sdk-core, crcmod\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=6177862f30eddbb8d5aa9f75ac1443e9fe9a0bc0e85ec9a1a1d1eb2a4ecd9c1d\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=9bf25f99bbd982ab5709fe8b391cb985746d7b739f9bf9652b3ee5e90164487c\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=a8b3b78532c6256bca94c86df83f76808ab788e1f08de751ec538940f9bf24d9\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112372 sha256=8fd3a096eea23f96cf348b5c90868ab3004dfbc99e61f1cc05eaea610985d1e1\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=392f88b74aae660cae91bff2dcc5b944942b2333334351db92cc519f9d44f6e1\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23470 sha256=0c3df7468d2bcff0dd89c20565d5b71d172390dedfe9d0f165598d0f91317584\n",
      "  Stored in directory: /home/asu/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval oss2 aliyun-python-sdk-core crcmod\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/asu/miniconda3/envs/dl_pytorch_hf/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: sentencepiece, pytz, py4j, py-spy, opencensus-context, nvidia-ml-py3, flatbuffers, distlib, cymem, crcmod, colorful, antlr4-python3-runtime, wrapt, wasabi, urllib3, tqdm, toolz, tifffile, tenacity, tabulate, spacy-loggers, spacy-legacy, shellingham, setuptools, PyWavelets, pydantic-core, pycryptodome, proto-plus, pdf2image, patsy, packaging, orjson, ordered-set, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, murmurhash, msgpack, llvmlite, jmespath, imageio, humanfriendly, graphviz, googleapis-common-protos, future, filelock, fastprogress, cloudpickle, cloudpathlib, catalogue, blis, annotated-types, xgboost, virtualenv, triton, tensorboardX, srsly, smart-open, scikit-learn, rich, requests, pytesseract, pydantic, preshed, plotly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, model-index, marisa-trie, lightning-utilities, lightgbm, lazy_loader, hyperopt, fastcore, coloredlogs, botocore, window-ops, utilsforecast, typer, statsmodels, seqeval, scikit-image, s3transfer, onnxruntime, nvidia-cusolver-cu12, language-data, google-api-core, gluonts, fastdownload, confection, catboost, aliyun-python-sdk-core, aiohttp-cors, weasel, torch, tokenizers, thinc, statsforecast, ray, opencensus, mlforecast, langcodes, gdown, boto3, aliyun-python-sdk-kms, transformers, torchvision, torchmetrics, spacy, pytorch-metric-learning, oss2, nlpaug, autogluon.common, accelerate, timm, pytorch-lightning, openxlab, fastai, autogluon.features, autogluon.core, optimum, opendatalab, lightning, autogluon.tabular, openmim, autogluon.timeseries, autogluon.multimodal, autogluon\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.5.1\n",
      "    Uninstalling setuptools-69.5.1:\n",
      "      Successfully uninstalled setuptools-69.5.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.13.1\n",
      "    Uninstalling filelock-3.13.1:\n",
      "      Successfully uninstalled filelock-3.13.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.3.1\n",
      "    Uninstalling triton-2.3.1:\n",
      "      Successfully uninstalled triton-2.3.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.0\n",
      "    Uninstalling scikit-learn-1.5.0:\n",
      "      Successfully uninstalled scikit-learn-1.5.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.3.5\n",
      "    Uninstalling rich-13.3.5:\n",
      "      Successfully uninstalled rich-13.3.5\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.0.dev0\n",
      "    Uninstalling transformers-4.42.0.dev0:\n",
      "      Successfully uninstalled transformers-4.42.0.dev0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.18.1\n",
      "    Uninstalling torchvision-0.18.1:\n",
      "      Successfully uninstalled torchvision-0.18.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.30.1\n",
      "    Uninstalling accelerate-0.30.1:\n",
      "      Successfully uninstalled accelerate-0.30.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "d2l 1.0.3 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
      "jupyterlab-server 2.25.1 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.6.0 accelerate-0.21.0 aiohttp-cors-0.7.0 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.0 autogluon.common-1.1.0 autogluon.core-1.1.0 autogluon.features-1.1.0 autogluon.multimodal-1.1.0 autogluon.tabular-1.1.0 autogluon.timeseries-1.1.0 blis-0.7.11 boto3-1.34.126 botocore-1.34.126 catalogue-2.0.10 catboost-1.2.5 cloudpathlib-0.18.1 cloudpickle-3.0.0 coloredlogs-15.0.1 colorful-0.5.6 confection-0.1.5 crcmod-1.7 cymem-2.0.8 distlib-0.3.8 fastai-2.7.15 fastcore-1.5.45 fastdownload-0.0.7 fastprogress-1.0.3 filelock-3.14.0 flatbuffers-24.3.25 future-1.0.0 gdown-5.2.0 gluonts-0.14.3 google-api-core-2.19.0 googleapis-common-protos-1.63.1 graphviz-0.20.3 humanfriendly-10.0 hyperopt-0.2.7 imageio-2.34.1 jmespath-0.10.0 langcodes-3.4.0 language-data-1.2.0 lazy_loader-0.4 lightgbm-4.3.0 lightning-2.1.4 lightning-utilities-0.11.2 llvmlite-0.43.0 marisa-trie-1.2.0 mlforecast-0.10.0 model-index-0.1.11 msgpack-1.0.8 murmurhash-1.0.10 nlpaug-1.1.11 nptyping-2.4.1 numba-0.60.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnx-1.16.1 onnxruntime-1.18.0 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.0 optimum-1.18.1 ordered-set-4.1.0 orjson-3.10.5 oss2-2.17.0 packaging-24.1 patsy-0.5.6 pdf2image-1.17.0 plotly-5.22.0 preshed-3.0.9 proto-plus-1.23.0 py-spy-0.3.14 py4j-0.10.9.7 pycryptodome-3.20.0 pydantic-2.7.4 pydantic-core-2.18.4 pytesseract-0.3.10 pytorch-lightning-2.1.4 pytorch-metric-learning-2.3.0 pytz-2023.4 ray-2.10.0 requests-2.28.2 rich-13.4.2 s3transfer-0.10.1 scikit-image-0.20.0 scikit-learn-1.4.0 sentencepiece-0.2.0 seqeval-1.2.2 setuptools-60.2.0 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 statsforecast-1.4.0 statsmodels-0.14.2 tabulate-0.9.0 tenacity-8.3.0 tensorboardX-2.6.2.2 thinc-8.2.4 tifffile-2024.5.22 timm-0.9.16 tokenizers-0.15.2 toolz-0.12.1 torch-2.1.2 torchmetrics-1.2.1 torchvision-0.16.2 tqdm-4.65.2 transformers-4.38.2 triton-2.1.0 typer-0.12.3 urllib3-1.26.18 utilsforecast-0.0.10 virtualenv-20.26.2 wasabi-1.1.3 weasel-0.4.1 window-ops-0.0.15 wrapt-1.16.0 xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "726432ad-94de-4102-9f48-c7cac7e1190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54ecef44-9baf-4450-84c7-0eff3e61f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 32)\n",
    "        self.fc5 = nn.Linear(32, 32)\n",
    "        self.fc6 = nn.Linear(32, 32)\n",
    "        self.fc7 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.sigmoid(self.fc7(x))\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = MLP(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3dc2334-a59f-40dc-9c90-5af1f746bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a03b15b6-068c-48b4-a5a4-82a3d4e8487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Train Loss: 0.6830, Val Loss: 0.6767, Val Accuracy: 0.5866\n",
      "Epoch 2/300, Train Loss: 0.6474, Val Loss: 0.5966, Val Accuracy: 0.7654\n",
      "Epoch 3/300, Train Loss: 0.5168, Val Loss: 0.4725, Val Accuracy: 0.7709\n",
      "Epoch 4/300, Train Loss: 0.4760, Val Loss: 0.4382, Val Accuracy: 0.8101\n",
      "Epoch 5/300, Train Loss: 0.4361, Val Loss: 0.4198, Val Accuracy: 0.8156\n",
      "Epoch 6/300, Train Loss: 0.4265, Val Loss: 0.4156, Val Accuracy: 0.8156\n",
      "Epoch 7/300, Train Loss: 0.4134, Val Loss: 0.4317, Val Accuracy: 0.7989\n",
      "Epoch 8/300, Train Loss: 0.4072, Val Loss: 0.4229, Val Accuracy: 0.8156\n",
      "Epoch 9/300, Train Loss: 0.3965, Val Loss: 0.4206, Val Accuracy: 0.8380\n",
      "Epoch 10/300, Train Loss: 0.3952, Val Loss: 0.4277, Val Accuracy: 0.8268\n",
      "Epoch 11/300, Train Loss: 0.3941, Val Loss: 0.4196, Val Accuracy: 0.8324\n",
      "Epoch 12/300, Train Loss: 0.3905, Val Loss: 0.4260, Val Accuracy: 0.8324\n",
      "Epoch 13/300, Train Loss: 0.3893, Val Loss: 0.4280, Val Accuracy: 0.8212\n",
      "Epoch 14/300, Train Loss: 0.3874, Val Loss: 0.4231, Val Accuracy: 0.8268\n",
      "Epoch 15/300, Train Loss: 0.3799, Val Loss: 0.4301, Val Accuracy: 0.8268\n",
      "Epoch 16/300, Train Loss: 0.3793, Val Loss: 0.4403, Val Accuracy: 0.8212\n",
      "Epoch 17/300, Train Loss: 0.3787, Val Loss: 0.4276, Val Accuracy: 0.8101\n",
      "Epoch 18/300, Train Loss: 0.3779, Val Loss: 0.4332, Val Accuracy: 0.8324\n",
      "Epoch 19/300, Train Loss: 0.3790, Val Loss: 0.4166, Val Accuracy: 0.8324\n",
      "Epoch 20/300, Train Loss: 0.3738, Val Loss: 0.4296, Val Accuracy: 0.8156\n",
      "Epoch 21/300, Train Loss: 0.3737, Val Loss: 0.4225, Val Accuracy: 0.8212\n",
      "Epoch 22/300, Train Loss: 0.3695, Val Loss: 0.4314, Val Accuracy: 0.8045\n",
      "Epoch 23/300, Train Loss: 0.3713, Val Loss: 0.4392, Val Accuracy: 0.7989\n",
      "Epoch 24/300, Train Loss: 0.3679, Val Loss: 0.4351, Val Accuracy: 0.8045\n",
      "Epoch 25/300, Train Loss: 0.3702, Val Loss: 0.4525, Val Accuracy: 0.8156\n",
      "Epoch 26/300, Train Loss: 0.3704, Val Loss: 0.4419, Val Accuracy: 0.8101\n",
      "Epoch 27/300, Train Loss: 0.3643, Val Loss: 0.4363, Val Accuracy: 0.8101\n",
      "Epoch 28/300, Train Loss: 0.3728, Val Loss: 0.4473, Val Accuracy: 0.8156\n",
      "Epoch 29/300, Train Loss: 0.3693, Val Loss: 0.4369, Val Accuracy: 0.8101\n",
      "Epoch 30/300, Train Loss: 0.3633, Val Loss: 0.4362, Val Accuracy: 0.8156\n",
      "Epoch 31/300, Train Loss: 0.3616, Val Loss: 0.4477, Val Accuracy: 0.7989\n",
      "Epoch 32/300, Train Loss: 0.3712, Val Loss: 0.4500, Val Accuracy: 0.7989\n",
      "Epoch 33/300, Train Loss: 0.3639, Val Loss: 0.4368, Val Accuracy: 0.8101\n",
      "Epoch 34/300, Train Loss: 0.3582, Val Loss: 0.4539, Val Accuracy: 0.8101\n",
      "Epoch 35/300, Train Loss: 0.3630, Val Loss: 0.4379, Val Accuracy: 0.8156\n",
      "Epoch 36/300, Train Loss: 0.3545, Val Loss: 0.4560, Val Accuracy: 0.8212\n",
      "Epoch 37/300, Train Loss: 0.3557, Val Loss: 0.4473, Val Accuracy: 0.8101\n",
      "Epoch 38/300, Train Loss: 0.3509, Val Loss: 0.4553, Val Accuracy: 0.8045\n",
      "Epoch 39/300, Train Loss: 0.3499, Val Loss: 0.4614, Val Accuracy: 0.8101\n",
      "Epoch 40/300, Train Loss: 0.3501, Val Loss: 0.4663, Val Accuracy: 0.7989\n",
      "Epoch 41/300, Train Loss: 0.3446, Val Loss: 0.4711, Val Accuracy: 0.7989\n",
      "Epoch 42/300, Train Loss: 0.3543, Val Loss: 0.4595, Val Accuracy: 0.8101\n",
      "Epoch 43/300, Train Loss: 0.3478, Val Loss: 0.4628, Val Accuracy: 0.7933\n",
      "Epoch 44/300, Train Loss: 0.3559, Val Loss: 0.4524, Val Accuracy: 0.8101\n",
      "Epoch 45/300, Train Loss: 0.3456, Val Loss: 0.4578, Val Accuracy: 0.8045\n",
      "Epoch 46/300, Train Loss: 0.3447, Val Loss: 0.4688, Val Accuracy: 0.8045\n",
      "Epoch 47/300, Train Loss: 0.3425, Val Loss: 0.4701, Val Accuracy: 0.7989\n",
      "Epoch 48/300, Train Loss: 0.3406, Val Loss: 0.4746, Val Accuracy: 0.8101\n",
      "Epoch 49/300, Train Loss: 0.3455, Val Loss: 0.4542, Val Accuracy: 0.8212\n",
      "Epoch 50/300, Train Loss: 0.3389, Val Loss: 0.4827, Val Accuracy: 0.7821\n",
      "Epoch 51/300, Train Loss: 0.3477, Val Loss: 0.4621, Val Accuracy: 0.8045\n",
      "Epoch 52/300, Train Loss: 0.3378, Val Loss: 0.4677, Val Accuracy: 0.8045\n",
      "Epoch 53/300, Train Loss: 0.3376, Val Loss: 0.4873, Val Accuracy: 0.7989\n",
      "Epoch 54/300, Train Loss: 0.3416, Val Loss: 0.4745, Val Accuracy: 0.8045\n",
      "Epoch 55/300, Train Loss: 0.3457, Val Loss: 0.4840, Val Accuracy: 0.8101\n",
      "Epoch 56/300, Train Loss: 0.3383, Val Loss: 0.4738, Val Accuracy: 0.8045\n",
      "Epoch 57/300, Train Loss: 0.3354, Val Loss: 0.4857, Val Accuracy: 0.7933\n",
      "Epoch 58/300, Train Loss: 0.3259, Val Loss: 0.5270, Val Accuracy: 0.7933\n",
      "Epoch 59/300, Train Loss: 0.3359, Val Loss: 0.4873, Val Accuracy: 0.8045\n",
      "Epoch 60/300, Train Loss: 0.3290, Val Loss: 0.4789, Val Accuracy: 0.8045\n",
      "Epoch 61/300, Train Loss: 0.3272, Val Loss: 0.4823, Val Accuracy: 0.8101\n",
      "Epoch 62/300, Train Loss: 0.3225, Val Loss: 0.5180, Val Accuracy: 0.8268\n",
      "Epoch 63/300, Train Loss: 0.3281, Val Loss: 0.4916, Val Accuracy: 0.7989\n",
      "Epoch 64/300, Train Loss: 0.3454, Val Loss: 0.5044, Val Accuracy: 0.7765\n",
      "Epoch 65/300, Train Loss: 0.3238, Val Loss: 0.5078, Val Accuracy: 0.8101\n",
      "Epoch 66/300, Train Loss: 0.3223, Val Loss: 0.4844, Val Accuracy: 0.7989\n",
      "Epoch 67/300, Train Loss: 0.3234, Val Loss: 0.5231, Val Accuracy: 0.8156\n",
      "Epoch 68/300, Train Loss: 0.3263, Val Loss: 0.5122, Val Accuracy: 0.7933\n",
      "Epoch 69/300, Train Loss: 0.3203, Val Loss: 0.5489, Val Accuracy: 0.7821\n",
      "Epoch 70/300, Train Loss: 0.3249, Val Loss: 0.5378, Val Accuracy: 0.7821\n",
      "Epoch 71/300, Train Loss: 0.3151, Val Loss: 0.5181, Val Accuracy: 0.7933\n",
      "Epoch 72/300, Train Loss: 0.3133, Val Loss: 0.5371, Val Accuracy: 0.8045\n",
      "Epoch 73/300, Train Loss: 0.3070, Val Loss: 0.5627, Val Accuracy: 0.7933\n",
      "Epoch 74/300, Train Loss: 0.3094, Val Loss: 0.5262, Val Accuracy: 0.7989\n",
      "Epoch 75/300, Train Loss: 0.3024, Val Loss: 0.5691, Val Accuracy: 0.7821\n",
      "Epoch 76/300, Train Loss: 0.3203, Val Loss: 0.5225, Val Accuracy: 0.7989\n",
      "Epoch 77/300, Train Loss: 0.3213, Val Loss: 0.5058, Val Accuracy: 0.8101\n",
      "Epoch 78/300, Train Loss: 0.3083, Val Loss: 0.5174, Val Accuracy: 0.7989\n",
      "Epoch 79/300, Train Loss: 0.3218, Val Loss: 0.5517, Val Accuracy: 0.7989\n",
      "Epoch 80/300, Train Loss: 0.3877, Val Loss: 0.4915, Val Accuracy: 0.7877\n",
      "Epoch 81/300, Train Loss: 0.3396, Val Loss: 0.4843, Val Accuracy: 0.8045\n",
      "Epoch 82/300, Train Loss: 0.3192, Val Loss: 0.5103, Val Accuracy: 0.8045\n",
      "Epoch 83/300, Train Loss: 0.3051, Val Loss: 0.5134, Val Accuracy: 0.8045\n",
      "Epoch 84/300, Train Loss: 0.3062, Val Loss: 0.5508, Val Accuracy: 0.8101\n",
      "Epoch 85/300, Train Loss: 0.3209, Val Loss: 0.5195, Val Accuracy: 0.8101\n",
      "Epoch 86/300, Train Loss: 0.3136, Val Loss: 0.5322, Val Accuracy: 0.8045\n",
      "Epoch 87/300, Train Loss: 0.3086, Val Loss: 0.5436, Val Accuracy: 0.7877\n",
      "Epoch 88/300, Train Loss: 0.3061, Val Loss: 0.5708, Val Accuracy: 0.8101\n",
      "Epoch 89/300, Train Loss: 0.3028, Val Loss: 0.5273, Val Accuracy: 0.8045\n",
      "Epoch 90/300, Train Loss: 0.3016, Val Loss: 0.5376, Val Accuracy: 0.8156\n",
      "Epoch 91/300, Train Loss: 0.3241, Val Loss: 0.5486, Val Accuracy: 0.8045\n",
      "Epoch 92/300, Train Loss: 0.2990, Val Loss: 0.5796, Val Accuracy: 0.7821\n",
      "Epoch 93/300, Train Loss: 0.2944, Val Loss: 0.5767, Val Accuracy: 0.7933\n",
      "Epoch 94/300, Train Loss: 0.2929, Val Loss: 0.5853, Val Accuracy: 0.7989\n",
      "Epoch 95/300, Train Loss: 0.2971, Val Loss: 0.5654, Val Accuracy: 0.8045\n",
      "Epoch 96/300, Train Loss: 0.2975, Val Loss: 0.5766, Val Accuracy: 0.7989\n",
      "Epoch 97/300, Train Loss: 0.2940, Val Loss: 0.6027, Val Accuracy: 0.8045\n",
      "Epoch 98/300, Train Loss: 0.2889, Val Loss: 0.5768, Val Accuracy: 0.8101\n",
      "Epoch 99/300, Train Loss: 0.2918, Val Loss: 0.6123, Val Accuracy: 0.8324\n",
      "Epoch 100/300, Train Loss: 0.2999, Val Loss: 0.5542, Val Accuracy: 0.8045\n",
      "Epoch 101/300, Train Loss: 0.3013, Val Loss: 0.5941, Val Accuracy: 0.8324\n",
      "Epoch 102/300, Train Loss: 0.2821, Val Loss: 0.5685, Val Accuracy: 0.8045\n",
      "Epoch 103/300, Train Loss: 0.2857, Val Loss: 0.6125, Val Accuracy: 0.8101\n",
      "Epoch 104/300, Train Loss: 0.2791, Val Loss: 0.6624, Val Accuracy: 0.8156\n",
      "Epoch 105/300, Train Loss: 0.2884, Val Loss: 0.6268, Val Accuracy: 0.8045\n",
      "Epoch 106/300, Train Loss: 0.2866, Val Loss: 0.6144, Val Accuracy: 0.8101\n",
      "Epoch 107/300, Train Loss: 0.2893, Val Loss: 0.6380, Val Accuracy: 0.8045\n",
      "Epoch 108/300, Train Loss: 0.2894, Val Loss: 0.6648, Val Accuracy: 0.8045\n",
      "Epoch 109/300, Train Loss: 0.2931, Val Loss: 0.6398, Val Accuracy: 0.8156\n",
      "Epoch 110/300, Train Loss: 0.3115, Val Loss: 0.5775, Val Accuracy: 0.7933\n",
      "Epoch 111/300, Train Loss: 0.3122, Val Loss: 0.5456, Val Accuracy: 0.8045\n",
      "Epoch 112/300, Train Loss: 0.2963, Val Loss: 0.5850, Val Accuracy: 0.8101\n",
      "Epoch 113/300, Train Loss: 0.2994, Val Loss: 0.5732, Val Accuracy: 0.8101\n",
      "Epoch 114/300, Train Loss: 0.2943, Val Loss: 0.5647, Val Accuracy: 0.8045\n",
      "Epoch 115/300, Train Loss: 0.2963, Val Loss: 0.5850, Val Accuracy: 0.8101\n",
      "Epoch 116/300, Train Loss: 0.2872, Val Loss: 0.6101, Val Accuracy: 0.8101\n",
      "Epoch 117/300, Train Loss: 0.2771, Val Loss: 0.6223, Val Accuracy: 0.7989\n",
      "Epoch 118/300, Train Loss: 0.2777, Val Loss: 0.5960, Val Accuracy: 0.8101\n",
      "Epoch 119/300, Train Loss: 0.2815, Val Loss: 0.5934, Val Accuracy: 0.8268\n",
      "Epoch 120/300, Train Loss: 0.2843, Val Loss: 0.6142, Val Accuracy: 0.8268\n",
      "Epoch 121/300, Train Loss: 0.2829, Val Loss: 0.6780, Val Accuracy: 0.8212\n",
      "Epoch 122/300, Train Loss: 0.2841, Val Loss: 0.6218, Val Accuracy: 0.8268\n",
      "Epoch 123/300, Train Loss: 0.2790, Val Loss: 0.6802, Val Accuracy: 0.8101\n",
      "Epoch 124/300, Train Loss: 0.2806, Val Loss: 0.6744, Val Accuracy: 0.8212\n",
      "Epoch 125/300, Train Loss: 0.2725, Val Loss: 0.6699, Val Accuracy: 0.8268\n",
      "Epoch 126/300, Train Loss: 0.2720, Val Loss: 0.6691, Val Accuracy: 0.8212\n",
      "Epoch 127/300, Train Loss: 0.2717, Val Loss: 0.6645, Val Accuracy: 0.8212\n",
      "Epoch 128/300, Train Loss: 0.2738, Val Loss: 0.6967, Val Accuracy: 0.8212\n",
      "Epoch 129/300, Train Loss: 0.2758, Val Loss: 0.6950, Val Accuracy: 0.8212\n",
      "Epoch 130/300, Train Loss: 0.2665, Val Loss: 0.7157, Val Accuracy: 0.8268\n",
      "Epoch 131/300, Train Loss: 0.2717, Val Loss: 0.7389, Val Accuracy: 0.8101\n",
      "Epoch 132/300, Train Loss: 0.2728, Val Loss: 0.6562, Val Accuracy: 0.8212\n",
      "Epoch 133/300, Train Loss: 0.2808, Val Loss: 0.7116, Val Accuracy: 0.8045\n",
      "Epoch 134/300, Train Loss: 0.2768, Val Loss: 0.7013, Val Accuracy: 0.8101\n",
      "Epoch 135/300, Train Loss: 0.2632, Val Loss: 0.7425, Val Accuracy: 0.8156\n",
      "Epoch 136/300, Train Loss: 0.2779, Val Loss: 0.7426, Val Accuracy: 0.7989\n",
      "Epoch 137/300, Train Loss: 0.2631, Val Loss: 0.6844, Val Accuracy: 0.8156\n",
      "Epoch 138/300, Train Loss: 0.2675, Val Loss: 0.7358, Val Accuracy: 0.8101\n",
      "Epoch 139/300, Train Loss: 0.2722, Val Loss: 0.7665, Val Accuracy: 0.8156\n",
      "Epoch 140/300, Train Loss: 0.2749, Val Loss: 0.7158, Val Accuracy: 0.8212\n",
      "Epoch 141/300, Train Loss: 0.2602, Val Loss: 0.8355, Val Accuracy: 0.7933\n",
      "Epoch 142/300, Train Loss: 0.2860, Val Loss: 0.7923, Val Accuracy: 0.8212\n",
      "Epoch 143/300, Train Loss: 0.2867, Val Loss: 0.6749, Val Accuracy: 0.8268\n",
      "Epoch 144/300, Train Loss: 0.2799, Val Loss: 0.6774, Val Accuracy: 0.7989\n",
      "Epoch 145/300, Train Loss: 0.2754, Val Loss: 0.7266, Val Accuracy: 0.8212\n",
      "Epoch 146/300, Train Loss: 0.2680, Val Loss: 0.7938, Val Accuracy: 0.8101\n",
      "Epoch 147/300, Train Loss: 0.2701, Val Loss: 0.6796, Val Accuracy: 0.8212\n",
      "Epoch 148/300, Train Loss: 0.2636, Val Loss: 0.7909, Val Accuracy: 0.8101\n",
      "Epoch 149/300, Train Loss: 0.2691, Val Loss: 0.7670, Val Accuracy: 0.8156\n",
      "Epoch 150/300, Train Loss: 0.2645, Val Loss: 0.7427, Val Accuracy: 0.8045\n",
      "Epoch 151/300, Train Loss: 0.2737, Val Loss: 0.7469, Val Accuracy: 0.8101\n",
      "Epoch 152/300, Train Loss: 0.2720, Val Loss: 0.7078, Val Accuracy: 0.7989\n",
      "Epoch 153/300, Train Loss: 0.2572, Val Loss: 0.8998, Val Accuracy: 0.7877\n",
      "Epoch 154/300, Train Loss: 0.2940, Val Loss: 0.8209, Val Accuracy: 0.8101\n",
      "Epoch 155/300, Train Loss: 0.2756, Val Loss: 0.7782, Val Accuracy: 0.7877\n",
      "Epoch 156/300, Train Loss: 0.2852, Val Loss: 0.6815, Val Accuracy: 0.7989\n",
      "Epoch 157/300, Train Loss: 0.2709, Val Loss: 0.6942, Val Accuracy: 0.8101\n",
      "Epoch 158/300, Train Loss: 0.2620, Val Loss: 0.7687, Val Accuracy: 0.8101\n",
      "Epoch 159/300, Train Loss: 0.2602, Val Loss: 0.7598, Val Accuracy: 0.8101\n",
      "Epoch 160/300, Train Loss: 0.2618, Val Loss: 0.7468, Val Accuracy: 0.8156\n",
      "Epoch 161/300, Train Loss: 0.2588, Val Loss: 0.8697, Val Accuracy: 0.7989\n",
      "Epoch 162/300, Train Loss: 0.2575, Val Loss: 0.8064, Val Accuracy: 0.8156\n",
      "Epoch 163/300, Train Loss: 0.2602, Val Loss: 0.8896, Val Accuracy: 0.8156\n",
      "Epoch 164/300, Train Loss: 0.2792, Val Loss: 0.7759, Val Accuracy: 0.8101\n",
      "Epoch 165/300, Train Loss: 0.2629, Val Loss: 0.8580, Val Accuracy: 0.7989\n",
      "Epoch 166/300, Train Loss: 0.2638, Val Loss: 0.8408, Val Accuracy: 0.8045\n",
      "Epoch 167/300, Train Loss: 0.2762, Val Loss: 0.7684, Val Accuracy: 0.8101\n",
      "Epoch 168/300, Train Loss: 0.2628, Val Loss: 0.7984, Val Accuracy: 0.8045\n",
      "Epoch 169/300, Train Loss: 0.2643, Val Loss: 0.9010, Val Accuracy: 0.7989\n",
      "Epoch 170/300, Train Loss: 0.2584, Val Loss: 0.8197, Val Accuracy: 0.8101\n",
      "Epoch 171/300, Train Loss: 0.2652, Val Loss: 0.8198, Val Accuracy: 0.8101\n",
      "Epoch 172/300, Train Loss: 0.2627, Val Loss: 0.7969, Val Accuracy: 0.8156\n",
      "Epoch 173/300, Train Loss: 0.2568, Val Loss: 0.8277, Val Accuracy: 0.8156\n",
      "Epoch 174/300, Train Loss: 0.2634, Val Loss: 0.8742, Val Accuracy: 0.8101\n",
      "Epoch 175/300, Train Loss: 0.2542, Val Loss: 0.8062, Val Accuracy: 0.8156\n",
      "Epoch 176/300, Train Loss: 0.2541, Val Loss: 0.8703, Val Accuracy: 0.8156\n",
      "Epoch 177/300, Train Loss: 0.2583, Val Loss: 0.8029, Val Accuracy: 0.8156\n",
      "Epoch 178/300, Train Loss: 0.2573, Val Loss: 0.9561, Val Accuracy: 0.7989\n",
      "Epoch 179/300, Train Loss: 0.2584, Val Loss: 0.8317, Val Accuracy: 0.7989\n",
      "Epoch 180/300, Train Loss: 0.2549, Val Loss: 0.9275, Val Accuracy: 0.7933\n",
      "Epoch 181/300, Train Loss: 0.2504, Val Loss: 1.0256, Val Accuracy: 0.7877\n",
      "Epoch 182/300, Train Loss: 0.2568, Val Loss: 0.8897, Val Accuracy: 0.8156\n",
      "Epoch 183/300, Train Loss: 0.2525, Val Loss: 0.9682, Val Accuracy: 0.8045\n",
      "Epoch 184/300, Train Loss: 0.2446, Val Loss: 1.1207, Val Accuracy: 0.7989\n",
      "Epoch 185/300, Train Loss: 0.2687, Val Loss: 1.0285, Val Accuracy: 0.7989\n",
      "Epoch 186/300, Train Loss: 0.2662, Val Loss: 0.8144, Val Accuracy: 0.8101\n",
      "Epoch 187/300, Train Loss: 0.2567, Val Loss: 0.9623, Val Accuracy: 0.7989\n",
      "Epoch 188/300, Train Loss: 0.2476, Val Loss: 0.8264, Val Accuracy: 0.8212\n",
      "Epoch 189/300, Train Loss: 0.2635, Val Loss: 0.9244, Val Accuracy: 0.8156\n",
      "Epoch 190/300, Train Loss: 0.2527, Val Loss: 0.9818, Val Accuracy: 0.7989\n",
      "Epoch 191/300, Train Loss: 0.2428, Val Loss: 0.9817, Val Accuracy: 0.8156\n",
      "Epoch 192/300, Train Loss: 0.2532, Val Loss: 0.9083, Val Accuracy: 0.8156\n",
      "Epoch 193/300, Train Loss: 0.2677, Val Loss: 0.9119, Val Accuracy: 0.8101\n",
      "Epoch 194/300, Train Loss: 0.2629, Val Loss: 0.9733, Val Accuracy: 0.8101\n",
      "Epoch 195/300, Train Loss: 0.2508, Val Loss: 0.9731, Val Accuracy: 0.8101\n",
      "Epoch 196/300, Train Loss: 0.2426, Val Loss: 0.9661, Val Accuracy: 0.8212\n",
      "Epoch 197/300, Train Loss: 0.2510, Val Loss: 0.8692, Val Accuracy: 0.8212\n",
      "Epoch 198/300, Train Loss: 0.2479, Val Loss: 1.0597, Val Accuracy: 0.7989\n",
      "Epoch 199/300, Train Loss: 0.2469, Val Loss: 0.9638, Val Accuracy: 0.8156\n",
      "Epoch 200/300, Train Loss: 0.2422, Val Loss: 1.6119, Val Accuracy: 0.7933\n",
      "Epoch 201/300, Train Loss: 0.2477, Val Loss: 1.1530, Val Accuracy: 0.8045\n",
      "Epoch 202/300, Train Loss: 0.2469, Val Loss: 1.5214, Val Accuracy: 0.8324\n",
      "Epoch 203/300, Train Loss: 0.2662, Val Loss: 1.5606, Val Accuracy: 0.8045\n",
      "Epoch 204/300, Train Loss: 0.2608, Val Loss: 1.0797, Val Accuracy: 0.8045\n",
      "Epoch 205/300, Train Loss: 0.2578, Val Loss: 0.9776, Val Accuracy: 0.8101\n",
      "Epoch 206/300, Train Loss: 0.2491, Val Loss: 0.9828, Val Accuracy: 0.8045\n",
      "Epoch 207/300, Train Loss: 0.2406, Val Loss: 1.0168, Val Accuracy: 0.8212\n",
      "Epoch 208/300, Train Loss: 0.2421, Val Loss: 1.0089, Val Accuracy: 0.8101\n",
      "Epoch 209/300, Train Loss: 0.2377, Val Loss: 1.0948, Val Accuracy: 0.8156\n",
      "Epoch 210/300, Train Loss: 0.2366, Val Loss: 1.6767, Val Accuracy: 0.8212\n",
      "Epoch 211/300, Train Loss: 0.2462, Val Loss: 1.1101, Val Accuracy: 0.8101\n",
      "Epoch 212/300, Train Loss: 0.2378, Val Loss: 1.2141, Val Accuracy: 0.7933\n",
      "Epoch 213/300, Train Loss: 0.2392, Val Loss: 1.0828, Val Accuracy: 0.7989\n",
      "Epoch 214/300, Train Loss: 0.2510, Val Loss: 1.7380, Val Accuracy: 0.7989\n",
      "Epoch 215/300, Train Loss: 0.2514, Val Loss: 1.0359, Val Accuracy: 0.8045\n",
      "Epoch 216/300, Train Loss: 0.2660, Val Loss: 1.6113, Val Accuracy: 0.8045\n",
      "Epoch 217/300, Train Loss: 0.2718, Val Loss: 0.9831, Val Accuracy: 0.7989\n",
      "Epoch 218/300, Train Loss: 0.2595, Val Loss: 1.5014, Val Accuracy: 0.7989\n",
      "Epoch 219/300, Train Loss: 0.2522, Val Loss: 1.0001, Val Accuracy: 0.8045\n",
      "Epoch 220/300, Train Loss: 0.2453, Val Loss: 1.0429, Val Accuracy: 0.8101\n",
      "Epoch 221/300, Train Loss: 0.2409, Val Loss: 1.1328, Val Accuracy: 0.8156\n",
      "Epoch 222/300, Train Loss: 0.2357, Val Loss: 1.7702, Val Accuracy: 0.8101\n",
      "Epoch 223/300, Train Loss: 0.2506, Val Loss: 1.1139, Val Accuracy: 0.8156\n",
      "Epoch 224/300, Train Loss: 0.2353, Val Loss: 1.7740, Val Accuracy: 0.7933\n",
      "Epoch 225/300, Train Loss: 0.2350, Val Loss: 1.7207, Val Accuracy: 0.8045\n",
      "Epoch 226/300, Train Loss: 0.2363, Val Loss: 1.7559, Val Accuracy: 0.7989\n",
      "Epoch 227/300, Train Loss: 0.2367, Val Loss: 1.1796, Val Accuracy: 0.7989\n",
      "Epoch 228/300, Train Loss: 0.2383, Val Loss: 1.8167, Val Accuracy: 0.7989\n",
      "Epoch 229/300, Train Loss: 0.2480, Val Loss: 1.6878, Val Accuracy: 0.8045\n",
      "Epoch 230/300, Train Loss: 0.2376, Val Loss: 1.1603, Val Accuracy: 0.8101\n",
      "Epoch 231/300, Train Loss: 0.2283, Val Loss: 2.3140, Val Accuracy: 0.7933\n",
      "Epoch 232/300, Train Loss: 0.2417, Val Loss: 1.1970, Val Accuracy: 0.8101\n",
      "Epoch 233/300, Train Loss: 0.2411, Val Loss: 2.1633, Val Accuracy: 0.8156\n",
      "Epoch 234/300, Train Loss: 0.2473, Val Loss: 2.1505, Val Accuracy: 0.8156\n",
      "Epoch 235/300, Train Loss: 0.2384, Val Loss: 1.7165, Val Accuracy: 0.8045\n",
      "Epoch 236/300, Train Loss: 0.2411, Val Loss: 1.6961, Val Accuracy: 0.7989\n",
      "Epoch 237/300, Train Loss: 0.2382, Val Loss: 2.3205, Val Accuracy: 0.7933\n",
      "Epoch 238/300, Train Loss: 0.2385, Val Loss: 1.2088, Val Accuracy: 0.8101\n",
      "Epoch 239/300, Train Loss: 0.2324, Val Loss: 1.7095, Val Accuracy: 0.8045\n",
      "Epoch 240/300, Train Loss: 0.2304, Val Loss: 2.2794, Val Accuracy: 0.7989\n",
      "Epoch 241/300, Train Loss: 0.2329, Val Loss: 2.3257, Val Accuracy: 0.8101\n",
      "Epoch 242/300, Train Loss: 0.2407, Val Loss: 1.2298, Val Accuracy: 0.7933\n",
      "Epoch 243/300, Train Loss: 0.2405, Val Loss: 2.3096, Val Accuracy: 0.7933\n",
      "Epoch 244/300, Train Loss: 0.2361, Val Loss: 2.2667, Val Accuracy: 0.8045\n",
      "Epoch 245/300, Train Loss: 0.2285, Val Loss: 2.2956, Val Accuracy: 0.8045\n",
      "Epoch 246/300, Train Loss: 0.2301, Val Loss: 2.3243, Val Accuracy: 0.8045\n",
      "Epoch 247/300, Train Loss: 0.2733, Val Loss: 1.7234, Val Accuracy: 0.8101\n",
      "Epoch 248/300, Train Loss: 0.2453, Val Loss: 1.6580, Val Accuracy: 0.8101\n",
      "Epoch 249/300, Train Loss: 0.2325, Val Loss: 2.3881, Val Accuracy: 0.7821\n",
      "Epoch 250/300, Train Loss: 0.2320, Val Loss: 2.3541, Val Accuracy: 0.7933\n",
      "Epoch 251/300, Train Loss: 0.2324, Val Loss: 2.3254, Val Accuracy: 0.8156\n",
      "Epoch 252/300, Train Loss: 0.2369, Val Loss: 2.2921, Val Accuracy: 0.8045\n",
      "Epoch 253/300, Train Loss: 0.2306, Val Loss: 2.3911, Val Accuracy: 0.8045\n",
      "Epoch 254/300, Train Loss: 0.2270, Val Loss: 2.4267, Val Accuracy: 0.8101\n",
      "Epoch 255/300, Train Loss: 0.2266, Val Loss: 2.3569, Val Accuracy: 0.7989\n",
      "Epoch 256/300, Train Loss: 0.2318, Val Loss: 2.4393, Val Accuracy: 0.8045\n",
      "Epoch 257/300, Train Loss: 0.2617, Val Loss: 2.1968, Val Accuracy: 0.8045\n",
      "Epoch 258/300, Train Loss: 0.2262, Val Loss: 2.9576, Val Accuracy: 0.7821\n",
      "Epoch 259/300, Train Loss: 0.2420, Val Loss: 1.7106, Val Accuracy: 0.8101\n",
      "Epoch 260/300, Train Loss: 0.2274, Val Loss: 2.2418, Val Accuracy: 0.7989\n",
      "Epoch 261/300, Train Loss: 0.2263, Val Loss: 2.7996, Val Accuracy: 0.8045\n",
      "Epoch 262/300, Train Loss: 0.2318, Val Loss: 2.8414, Val Accuracy: 0.7877\n",
      "Epoch 263/300, Train Loss: 0.2272, Val Loss: 2.8759, Val Accuracy: 0.7989\n",
      "Epoch 264/300, Train Loss: 0.2280, Val Loss: 2.3657, Val Accuracy: 0.8045\n",
      "Epoch 265/300, Train Loss: 0.2243, Val Loss: 4.3663, Val Accuracy: 0.7933\n",
      "Epoch 266/300, Train Loss: 0.2270, Val Loss: 3.9231, Val Accuracy: 0.7877\n",
      "Epoch 267/300, Train Loss: 0.2259, Val Loss: 2.9075, Val Accuracy: 0.7989\n",
      "Epoch 268/300, Train Loss: 0.2286, Val Loss: 4.4325, Val Accuracy: 0.7598\n",
      "Epoch 269/300, Train Loss: 0.2373, Val Loss: 1.1122, Val Accuracy: 0.7709\n",
      "Epoch 270/300, Train Loss: 0.2723, Val Loss: 2.3372, Val Accuracy: 0.8101\n",
      "Epoch 271/300, Train Loss: 0.2925, Val Loss: 2.0902, Val Accuracy: 0.8101\n",
      "Epoch 272/300, Train Loss: 0.2659, Val Loss: 1.0046, Val Accuracy: 0.7989\n",
      "Epoch 273/300, Train Loss: 0.2371, Val Loss: 1.6857, Val Accuracy: 0.8045\n",
      "Epoch 274/300, Train Loss: 0.2266, Val Loss: 1.6871, Val Accuracy: 0.7989\n",
      "Epoch 275/300, Train Loss: 0.2247, Val Loss: 1.7313, Val Accuracy: 0.7933\n",
      "Epoch 276/300, Train Loss: 0.2253, Val Loss: 1.7243, Val Accuracy: 0.8045\n",
      "Epoch 277/300, Train Loss: 0.2284, Val Loss: 1.6962, Val Accuracy: 0.8045\n",
      "Epoch 278/300, Train Loss: 0.2311, Val Loss: 1.8141, Val Accuracy: 0.7877\n",
      "Epoch 279/300, Train Loss: 0.2224, Val Loss: 1.8487, Val Accuracy: 0.7933\n",
      "Epoch 280/300, Train Loss: 0.2179, Val Loss: 4.8311, Val Accuracy: 0.7933\n",
      "Epoch 281/300, Train Loss: 0.2316, Val Loss: 1.7953, Val Accuracy: 0.7877\n",
      "Epoch 282/300, Train Loss: 0.2347, Val Loss: 3.2906, Val Accuracy: 0.7821\n",
      "Epoch 283/300, Train Loss: 0.2288, Val Loss: 1.8075, Val Accuracy: 0.7989\n",
      "Epoch 284/300, Train Loss: 0.2218, Val Loss: 3.3728, Val Accuracy: 0.7933\n",
      "Epoch 285/300, Train Loss: 0.2224, Val Loss: 1.8952, Val Accuracy: 0.7989\n",
      "Epoch 286/300, Train Loss: 0.2173, Val Loss: 3.8649, Val Accuracy: 0.7821\n",
      "Epoch 287/300, Train Loss: 0.2179, Val Loss: 2.9278, Val Accuracy: 0.7877\n",
      "Epoch 288/300, Train Loss: 0.2184, Val Loss: 2.8633, Val Accuracy: 0.7989\n",
      "Epoch 289/300, Train Loss: 0.2185, Val Loss: 3.4078, Val Accuracy: 0.7933\n",
      "Epoch 290/300, Train Loss: 0.2216, Val Loss: 4.3927, Val Accuracy: 0.7821\n",
      "Epoch 291/300, Train Loss: 0.2809, Val Loss: 2.9832, Val Accuracy: 0.7765\n",
      "Epoch 292/300, Train Loss: 0.2487, Val Loss: 2.9135, Val Accuracy: 0.7654\n",
      "Epoch 293/300, Train Loss: 0.2330, Val Loss: 1.7952, Val Accuracy: 0.7933\n",
      "Epoch 294/300, Train Loss: 0.2242, Val Loss: 2.4185, Val Accuracy: 0.7989\n",
      "Epoch 295/300, Train Loss: 0.2265, Val Loss: 1.7848, Val Accuracy: 0.8268\n",
      "Epoch 296/300, Train Loss: 0.2182, Val Loss: 2.8969, Val Accuracy: 0.8045\n",
      "Epoch 297/300, Train Loss: 0.2231, Val Loss: 3.3981, Val Accuracy: 0.8101\n",
      "Epoch 298/300, Train Loss: 0.2156, Val Loss: 3.3937, Val Accuracy: 0.8045\n",
      "Epoch 299/300, Train Loss: 0.2126, Val Loss: 2.4319, Val Accuracy: 0.7989\n",
      "Epoch 300/300, Train Loss: 0.2136, Val Loss: 3.9679, Val Accuracy: 0.7989\n",
      "Best Validation Accuracy: 0.8380\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.round()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 300\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(f'Best Validation Accuracy: {best_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c9b198e-b9c6-4aa1-a3de-7db8b70fda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# 转换测试集为 PyTorch 张量\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# 使用模型进行预测\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.to(device))\n",
    "    test_preds = test_outputs.round().cpu().numpy()\n",
    "\n",
    "# 生成提交文件\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data[\"PassengerId\"],\n",
    "    \"Survived\": test_preds.flatten().astype(int)\n",
    "})\n",
    "submission.to_csv('submission2.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f6853-d3c5-4082-9b38-8fd1d34d00bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
